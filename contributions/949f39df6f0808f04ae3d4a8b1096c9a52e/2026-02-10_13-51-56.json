{
  "id": 949,
  "activeVersion": 13,
  "score": 24,
  "votableId": 6455265,
  "codingamerId": 484004,
  "views": 1569,
  "commentableId": 6395233,
  "title": "Monte Carlo Tree Search exercise",
  "status": "ACCEPTED",
  "type": "PUZZLE_INOUT",
  "nickname": "aCat",
  "publicHandle": "949f39df6f0808f04ae3d4a8b1096c9a52e",
  "codingamerHandle": "b528dd3b279d7578674a1129305918e0400484",
  "lastVersion": {
    "version": 13,
    "data": {
      "title": "Monte Carlo Tree Search exercise",
      "topics": [
        {
          "id": 92,
          "handle": "MCTS",
          "labelMap": {
            "1": "Monte Carlo tree search",
            "2": "Monte Carlo tree search"
          },
          "puzzleCount": 1,
          "parentTopicId": 41
        },
        {
          "labelMap": {
            "2": "UCT"
          }
        },
        {
          "labelMap": {
            "2": "UCB1"
          }
        }
      ],
      "solution": "import sys\nimport math\n\n\"\"\"#\n# GENERATOR\nC=1.41\nminD=10\nmaxD=16\nmaxB=2\nminScore=0.0\nmaxScore=1.0\nplayouts=400\nprint (playouts, C)\nimport random\nplays = set()\nwhile len(plays) < playouts:\n    moves = ''.join([chr(ord('a')+random.randint(0, maxB-1)) for j in range(random.randint(minD, maxD))])\n    isPrefix = False\n    for m in plays:\n        if len(moves) != len(m) and (m.startswith(moves) or moves.startswith(m)):\n            isPrefix = True\n            break\n    if not isPrefix:\n        plays.add(moves)\n        print ('{} {:.2f}'.format(moves, random.random()*(maxScore-minScore)+minScore))\nsys.exit(0)\n#\"\"\"#\n\n\nclass MCTSNode:\n    q = 0\n    n = 0\n    children = {}\n\n    def __init__(self, visits=0, score=0):\n        self.n = visits\n        self.q = score\n        self.children = {}\n\n    # this is cheating because normally we cant backpropagate going forward ^^\n    def treeExtendAndBackprop(self, playout, score):\n        self.n += 1\n        self.q += score\n        node = self\n        for a in playout:\n            if not a in node.children:\n                node.children[a] = MCTSNode(1, score)\n                break\n            node = node.children[a]\n            node.n += 1\n            node.q += score\n\n    def treePolicy(self, C):\n        bestactions=''\n        node = self\n        while node.children:\n            bestscore = -99999.00\n            bestaction = ''\n            for a, v in node.children.items():\n                score = v.q/v.n + C * math.sqrt(math.log(node.n)/v.n)\n                print (bestactions+a, score, file=sys.stderr)\n                if score > bestscore or (score==bestscore and a < bestaction):\n                    bestscore = score\n                    bestaction = a\n            bestactions += bestaction\n            node = node.children[bestaction]\n        return bestactions\n\n\nn, C = input().split()\nn = int(n)\nC = float(C)\n\nroot = MCTSNode()\n\nfor i in range(n):\n    playout, score = input().split()\n    root.treeExtendAndBackprop(playout, float(score))\n\nprint(root.treePolicy(C))\n\n",
      "statement": "Assume we are dealing with (nondeterministic) one-player game. To find an optimal sequence of movements we could use Monte Carlo Tree Search algorithm (https://en.wikipedia.org/wiki/Monte_Carlo_tree_search). \n\nThus, we perform a number of so-called playouts, and gradually build an MCTS tree that will help us choosing statistically best choices for each turn of the game. A playout is a sequence of moves reaching the game tree leaf, so it has assigned a true score. It consists of two parts: the beginning, which is selected by the algorithm using the UCT formula; and the remaining part which is usually a random sequence of movements.\n\nIn this puzzle, we are given a list of playouts (encoded as words, where each letter is a single move) with assigned scores, that should be used to build an MCTS tree. After building a tree, the task is to return the sequence of moves, reaching the MCTS tree leaf, that will be chosen using UCT policy given exploration/exploitation constant {{C}}.\n\nFor given node [[N]] visited [[N.v]] times, according to the UCB1 formula we should choose a child [[M]] that maximizes the value given by: [[M.s/M.v + C*sqrt(ln(N.v)/M.v)]], where [[M.v]] is number of visits in node [[M]] and [[M.s]] is sum of scores obtained for this node (so the first component of the sum is average score for node [[M]]).\n\n<<Final remarks:>>\n- Note that this puzzle differs form the real-life-scenario where the playouts are not given, but they are also computed using UCT+random policies.\n- In standard implementations you are forced to choose an unexplored move if such exists. Here we assume that after reading the playout data we do not have such moves in the non-leaf nodes of the MCTS tree.\n- A tie-breaking rules when comparing UCT values is the ordering on letters (i.e. smaller letter should be chosen).\n\n<<Example explanation:>>\n- Reading {{baa 30}} will create child node labeled {{b}} with avg. score 30 and one visit. The MCTS tree root will have the same statistics. Note that we are adding only one new node at a time.\n- Reading {{ab 20}} will create another child node for the root, updating its statistics.\n- Finally, reading {{bbb 4}} will create a new node on a path {{bb}} from the root, updating all statistics on a way to the root, so the root will have 3 visits, and {{b}} node 2 visits.\n- Choosing move from the root based on the UCB1 formula will favor move {{a}} (average score 20), instead of move {{b}} (average score 17). This is because the small value of constant {{C}}, makes the exploration part of the equation not significant.\n- As there are no further nodes in MCTS tree along that paths, the 1-move sequence {{a}} is the answer.",
      "testCases": [
        {
          "title": "Tiny tree test",
          "isTest": true,
          "testIn": "3 0.1\nbaa 30\nab 20\nbbb 4",
          "testOut": "a",
          "isValidator": false,
          "needValidation": true
        },
        {
          "title": "Tiny tree validator",
          "isTest": false,
          "testIn": "3 0.1\nbaa 30\nab 20\naaa 4",
          "testOut": "b",
          "isValidator": true,
          "needValidation": true
        },
        {
          "title": "Nondeterministic scores test",
          "isTest": true,
          "testIn": "5 0.5\naaa 0.6\nbaa 1.0\naab 0.1\nbaa 0.2\naaa 0.2",
          "testOut": "ba",
          "isValidator": false,
          "needValidation": true
        },
        {
          "title": "Nondeterministic scores validator",
          "isTest": false,
          "testIn": "6 0.6\nbbb 0.6\nbaa 0.8\naab 0.1\nbaa 0.2\nbbb 0.1\nabba 0.5",
          "testOut": "ab",
          "isValidator": true,
          "needValidation": true
        },
        {
          "title": "Significant exploration test",
          "isTest": true,
          "testIn": "3 1.0\nac 1.0\nbc 1.0\nad 1.1",
          "testOut": "b",
          "isValidator": false,
          "needValidation": true
        },
        {
          "title": "Significant exploration validator",
          "isTest": false,
          "testIn": "4 15.0\nacde 20\nbadc 17\nad 25\naca 24.6",
          "testOut": "b",
          "isValidator": true,
          "needValidation": true
        },
        {
          "title": "UCB1-tie test",
          "isTest": true,
          "testIn": "4 0.5\ndda 20\ndad 21\ncba 20\nchb 21",
          "testOut": "ch",
          "isValidator": false,
          "needValidation": true
        },
        {
          "title": "UCB1-tie validator",
          "isTest": false,
          "testIn": "6 0.23\ndda 30\ndda 30\ndda 30\ncba 20\nceaa 35\ncfa 35",
          "testOut": "ce",
          "isValidator": true,
          "needValidation": true
        },
        {
          "title": "Small random test",
          "isTest": true,
          "testIn": "10 0.3\nbbbaa -7.35\naabab -0.76\nbbaa 14.81\nbbaa 18.51\naabaa 16.46\nbbabb 15.25\nbbabb 5.71\nbabb -1.89\nababa -5.15\naaaa -7.90",
          "testOut": "bbabb",
          "isValidator": false,
          "needValidation": true
        },
        {
          "title": "Small random validator",
          "isTest": false,
          "testIn": "10 0.5\nccaab -8.85\nacaccb -1.05\ncbcccc 18.03\nbaccb 16.53\nbabbc 17.40\nabbaa -8.89\ncbccbcb 1.34\nbbbbbcc 13.51\ncbaccac 5.95\ncbcb -5.37",
          "testOut": "ba",
          "isValidator": true,
          "needValidation": true
        },
        {
          "title": "Large test",
          "isTest": true,
          "testIn": "250 4.4\nbaabbabbaacbacabccc 2.15\nacacabbbccbcbbac 6.29\ncbbabacacabbaaacbbbbccb 15.98\nabbcbcbcbbbccbacbacbac 7.45\ncabbbbbccbaabbbaaaba 9.61\ncaabcacbbcabbaccaaaabcca 2.65\nbaabbabaaacaabccaaacbbca 16.38\nabaabbacbbaacaabccccbaab 5.69\nbbbcaaacbcaabbbbcabaab 2.52\nbbbccabccbaacbbc 14.52\nacbbbbcccccabcaabbcbbbccc 11.86\nbbbccaacacabaaacaccbcbbcc 11.05\ncaaccccbccbcacbcbabbab 12.77\ncbbbaababcbacaca 3.98\nccbaacabbbbabba 12.16\nbacbbbaaaaabbcbccaccccabb 3.08\nbaaabbccbbbabbcccabac 6.20\nbbabcaabaccbcaaacabbbcb 11.04\naaccbbbbaaaabaaacba 8.71\nacabbabbacbacacbbbbcba 1.59\nccaaacabcccacac 18.02\nabaabcccbcabbacaccccbabba 19.69\ncbcacaacbacbcacac 1.65\nacccbacbbcbbbcbacc 10.88\nabccccbccacababbabbcc 16.70\nabcbcaaabaaaaabc 12.48\naaabcacbccbcbccbababaa 2.37\ncbbcbbcbccabcccbaccbc 14.85\ncbbbbbbccabcbbcac 17.65\nbcbcaabbabaccbbaccacccbcb 3.68\nbcbcbcbbaaabacabcbbaccc 14.03\nabcaabababcabcbacabbcbbb 10.23\nccaababcabbccbcaaaacabac 0.59\nabacbcbccccaabbca 6.11\nbcbbcaacabbccbabccc 7.32\ncabbbacabbaacbacb 4.51\nacabcbacababbacabac 9.29\naacabaacaccccacbbcabcaacb 8.83\nacaaccbaccabacacbc 13.63\ncbbaacabccabbac 9.65\nbcbababaaccbcbccccaa 6.02\ncbacbbaccbacaaa 10.32\nbababbcbbcaaaccccbbaaa 7.15\ncbabacbcabcabaccaabcbcbaa 16.95\nabacbbacaccaaacbaccab 3.63\nacbaaccaaacaacaccbc 9.61\ncbcacaaaacbcccaca 4.20\nabbcccccbcccacbbbcbbbcb 2.14\ncbbabccaabccbaccbccbac 18.16\nbbcbbbacabccbca 2.76\naabaccbcacabccacb 11.26\ncababccbcbbccbbaccacaccbc 1.20\nabcabbcbcccaaab 6.94\nacbbcacaacbccaacccabb 17.85\ncbbbabcacbccaccaabc 1.06\nbccabccacabbbabacabb 14.83\ncbccacaccbcbbcbbcbb 4.15\nacccaccabaabbbbc 12.80\nbbabaababcbccccaacac 12.97\nacaaccbcbcbbccccab 17.55\nacabacbaacabbcc 3.28\nbbabcaaababacbbcbac 9.10\ncaccccabbacabcccccbbbbacc 0.63\naabacacaabacabbbbba 7.90\ncbcbabaaabcaaccacaab 8.40\nacaabbbbaacacbbaaaaacabac 7.48\nbbbbcbccabbcaaaabacb 9.48\nbaabbaabccaaaacbccacbbca 10.36\nabcababcbbbaacacaacccbca 13.00\naccacabcbaaababcabacbbabb 18.61\ncbcbacabbcabaacaabbac 3.48\ncbababcbcbbacbcb 7.33\nccacaccbbcbcabbbbcc 19.13\nbcbabaabbbbaababab 11.86\nbaabbbbacbacaccb 14.28\nccbabaacccacbcba 18.22\nbcbccabbbabcbacc 0.13\nabcacbbbbacccbc 17.33\nbbbaaaacbcbaaacccca 10.24\ncbacabaaccabbcac 11.96\ncaababaaccbbcbcaabbaaca 6.65\nbbbaabccbbccbacbaabbccca 6.89\nbaabacaaabbccacbbabccac 10.71\nbbcabaabaabcaabacccbcacac 3.46\ncabbccbbabbccbccbaaac 10.20\nbbbabacbbabbbacccbbaaacb 13.42\nbcbcabbbbcbccaa 19.82\nbccaabbacccbbccbaca 7.07\naaaaccaabbabccbbcabbabc 0.91\naacaaaaacacaccacbb 19.43\ncbccbabccccaabc 17.29\nababbbbababbbbccaabbb 17.61\nacbcaaaabbbababbbbcc 9.54\nacacacbbbbcccbcaa 17.91\naabcabbcaacbaacbb 13.49\ncaccacabacccbacbbacbabac 0.62\nbbccaabbccbaabccbb 17.12\nbaaabbabbacbcacccccbcbc 17.17\ncaaaccccbaacacbbccaabb 9.32\nccaabcbcacaababbab 5.59\ncabccaaabcccbabcaabcaaaac 17.73\nccccabbabcbbccac 7.63\nabcbabcbcbbbcaa 8.62\nbbcaccbbbbcbccbccbaccabc 1.64\nbacbacccaaaabcabcaacccb 17.38\nbacacbbbbcbabbaacccabcbc 17.78\ncbbccbcbbabcabbccbccbb 2.20\nbabcbcacaabccabc 8.71\ncbabaaababacaabaabba 13.80\ncaabaccaacbbbbbbcbcaaca 18.28\nbcababccccabccbbacccb 10.52\nccbbaabbabaabcaacaabc 10.33\nabcccacaaccbaabb 13.92\nabcccbcbcaacacaacc 3.58\nccccabcbbbaccaabcba 14.26\nbcacabacaabacacb 4.63\ncbbacabcaaccababbbc 11.75\naabbcababaccbacabbbaccbbb 6.76\nbccbcbcbcacbaccaba 10.64\nababcbaaaacccaccacacabcac 13.66\ncbabaaccaaaacccb 5.07\nbccbcbaccabbbaacb 6.94\nbbabbccaccabacbacaccbb 3.29\nacacaabacbacbcbaabbacbbc 15.51\ncbcababcbaacbccbcbbbcbacb 6.85\nbaccbcbbbbaabcabbc 18.18\ncccccbabbaccabbccb 14.08\nabacaacaacbaaaa 13.05\nbacabbacbccbabacbccc 3.07\nbacbcabbccccabcb 2.72\nbcbbacbbacaabbbbcbbacbac 17.39\nbaccbccabaccabbbbbccbbb 17.93\nbbcbacbbacabaabacbabcaaaa 1.37\nccabbbaabbcbcba 2.74\nbabaccaccacbbbcbabcaaa 7.99\ncaacabbbacacaabbabaacbc 8.26\nacabcbababbccbbcbbbcccaa 11.83\ncbbabbacccbacbacacbc 3.37\ncccbabcbbbbcbbcbcbcc 9.09\nacacaabcaacbbaacbacb 10.87\nbcaaaababacabbaa 17.85\nbccabaabbbbcbcaaaaacc 4.03\naabbaaabcabcaabbbbba 1.74\nbbbbacaabbcaabbacabcac 17.80\nbbbccbcbacbaaaacabbb 14.35\nabbccbacacccaaaacacbcbcc 5.82\nbbacbcbcbabaacccccc 0.03\nbacabbccccccacbaacbcca 14.28\ncbacbcaacccbaab 7.95\nbbbcabcbabcbabacbbbaaac 4.90\nabbbaccaaabcbcbbcc 9.71\nababccabbcbbbabcbabaacbb 11.66\ncabcaabcabacacbcacbcca 2.26\nccbcbccbcbccbac 14.37\nccaabcbcaaaaaaaabbbacaa 5.96\ncaccaccccccccacacabcbbb 16.64\ncabbacbbacaaaaa 9.33\ncbcbcacaabbaacccbbcb 8.84\nbcaaaacabbbbbaca 16.03\nacacbbcacaccccbb 1.16\nabcacabaccabaabbcaabbabac 17.40\ncbbcabbababaabcabacaaab 6.55\nccbcacababcbbaaabacbbaab 16.32\nacaaaaacaacbbacabbb 6.05\ncaaaaaabaababcbaacabba 16.02\nabbacccbbaababbcbbaabcab 10.30\ncbababcbccccbaaacacaccaa 0.94\nacccabcbaacbbbabc 2.40\nbbcabaccabbbcbbbababbacc 2.87\ncbcbbbcbcbcccbca 3.45\naccbaccbbcbacccaab 10.12\ncaaccbaabaabbccacaacb 13.25\nccbaababcacacbaccabba 4.07\nbbbaccbcabcbbcb 13.86\ncbcccaccbbacccbbbccbcabba 8.75\ncababcccbabaababaabab 10.88\ncabbcbaccbcbababababccbba 8.22\ncccaaacbabbaaaa 7.34\naccbacbbbabcaaabbbbaabacc 2.11\ncabcbbaabbbcaaaaaacaccbba 14.91\ncacbbcbbccbacab 7.14\nacaabbccbcbcbbabc 15.73\nbcccaaacbbaaabb 12.89\nccabbcbcbcabcaabcccacaaca 16.50\nbbabbabbabacaba 11.07\nbbaabbbabcbcbbbcbbbbcaabc 9.23\nbccbccbbbbccccc 14.16\ncacbcbbabccacbab 13.52\ncbbaabaaaabaccabcbbccb 5.17\nbbaaabbcaaabaabbbbaa 9.52\nbbbaaabaccabbbab 13.91\ncbcbacababaababcaabcaabc 18.24\naabbaccbaacbccbcaabbcac 9.08\nbccbababbcaacbaaa 5.58\nbcbabaccabaaaabcbcbbcbaab 12.22\nacbbbbbacccbbccbcababcbc 5.93\nacabbcbbccbccbcacb 14.85\ncbccbcabccaccbbbaabc 17.98\nbbaccacbabaabbbccababcaa 12.53\naaacabccabcabaa 12.48\nbacccbbabbbaabcabccc 6.87\nccacaaaacaaabccbbabacbab 18.19\naacacabaaaaccbabacbabaa 14.02\naacbbccbcaacabb 16.29\nbaaabbcababaabbcabcaaabbb 11.83\naabcbaaaccbcbcbaa 6.87\nbcbbccacbbcbccbccccccbbca 9.97\nbaabaacbacabacccccbbb 1.40\ncbaacbcbccaccbbaacb 7.24\nbaabbccabbaabbcbccaacc 6.92\nbccbcacbcbbbcaaccbabbabba 3.65\ncccbcbabcbbcbacacacbba 3.51\nbabaabccaacbaccb 3.77\nbcacaabcbbbbacbcab 2.04\naabacaccbcabcaac 14.36\nbbbaabccaaabcbbab 9.86\nccbbbccaaaaabbbcbababba 2.86\ncaaaaaaabbcaabbaccaacabbc 17.63\ncccacaabcccaaabbcbcaaccba 17.81\naabbcccbcaaacbbaba 12.06\nccccbaccaaccacabbcccabcbb 9.67\ncccaaabcbabaacbccccabccc 10.43\nbbacacccbccaacaa 5.49\ncacbbbbbbbbabbabcbcbacb 17.44\nbcaacbbcabbaabcacbb 7.74\nccaabacacccbccacacaac 15.93\nbcaaacabbcabbcbc 0.80\nacacbcccbbabbaacb 6.93\nccaabcccbcacabaccba 7.80\naaaaccbabcbacbbbb 17.94\ncbababacbabbabcb 0.83\nbccbbaaaaaaabbbabbbb 7.08\ncbbbacaabbccbaabcbcbab 11.51\nbbbaaccacbbabacaab 16.02\nbaaccabacbcacbbbccbca 5.75\ncacbaaaaaaacbaccaaaaa 4.57\nbbcabcbcbbcbaccabbabbabbb 14.39\nacaccbcbbbbcaaacccbc 14.24\nacbaaabcacbaaaaa 17.34\naaacabbaccbcaacaac 6.68\nccbcaacaacbcacbccccaabbc 15.74\nbacabcbabbbccccbcacabcbcb 9.02\nabaacaabacbabccaacac 6.89\nccbbbabcacacccc 8.23\ncccaaabbabbabccb 14.71\nabacaaccbacaacccacbbbbb 18.10\naabcaccacaaccbbcbcabbcb 10.05\ncbcbbcabaccabcbcbbbcaac 9.26\nbaabaacacbbacbbbcaccbaa 11.34\ncbccbcbcbcaaacb 6.64",
          "testOut": "abcaca",
          "isValidator": false,
          "needValidation": true
        },
        {
          "title": "Large validator",
          "isTest": false,
          "testIn": "300 10\nccbcbaaaccacaaaa 14.74\nccbababcbaaca 7.75\nabcbbcaabaacaaa 9.63\ncbbababccba 11.22\ncaabcacbca 3.07\ncbaabccaccc 10.40\nbabababbcbccabba 2.75\nbcbbbcaccacbca 21.78\nabcbbabcbbbabcba 4.23\ncbaccbabaabbbbb 16.05\nabaccccccbc 7.44\nacaababaacacc 13.26\nccabacbbaa 19.42\ncabaacabaccbc 24.07\naaacbcababacb 6.66\nbacaabaabcc 2.92\ncbbcbbaaacacabbc 17.45\nbbaccccacbbbaa 6.69\nabaaacbcbbbc 2.66\naaccacabbca 5.94\ncbbbcbacacaaa 15.55\naacbbcccbcb 16.42\nabcaccbccbcb 19.00\ncbcaaccbbaab 7.10\naaabbbccbab 21.66\nacbbcbccabbbabbcc 11.29\ncaccabbaacaacac 6.86\nbacbbabccbbabac 1.89\nccacaaabcbbcab 15.44\ncaccbccabcac 23.49\ncccabcabacabcaab 17.26\nabacbabcaa 14.30\nbcabbccbccbabcaba 15.68\nbbbbaaaabbbcbcc 15.32\nccccbcbacbcbcb 1.13\naaccabbcbcc 24.45\ncbcbbbcbac 24.98\ncabbaacabccccaaa 23.41\nbababcbabaaaac 20.45\ncccabccbbccacaccc 22.89\nbbabbcbbbaabaca 16.63\nabaacbbbbbbac 0.40\nbbabbbccaa 1.09\nacaacacbabaabbbba 16.24\naabacaccac 14.23\nabaaacccbcaacba 10.82\nbccacacaaaa 13.77\nabcbbbacaabcacb 4.29\nbbaaacbbccaa 9.49\nacaacacacbaaccca 18.50\nccbcaabacaabbbab 9.49\nabcabbccccaa 15.90\nbabaaccacbcccca 13.38\nbccbabbbcbbbbaaa 15.60\nacbccbcaab 15.21\nbbaababccacbcacbb 22.61\ncbbbaabbcbbbacbc 13.66\naccaabcaabaaccb 22.75\naabbbbaaaaa 19.16\ncacccbccacaa 6.46\ncbabcabbccbbbca 18.64\naaacbbbccacbabbcc 9.56\nbcacbaaccbaa 15.22\nccabccbbbb 3.22\nbcbabcbccbbcacc 23.72\naabcbaabbbcbca 2.39\nabcababbac 7.17\ncaabbcccccbaabca 13.07\ncbcbcccaccb 11.41\ncbabbbcbabbbbb 12.34\ncbabbbcbbabacb 11.58\nbcbacbcaccccbacb 18.10\nbaabccacabaa 7.14\nbcbaabbbbbbbccbcb 20.26\nbcbacbbabaaccc 15.48\naacbbcbbcbcbbbcc 20.52\ncccbabbacb 15.46\nacaacaaaaaccbcc 16.99\ncacbaacbcacccbccc 15.10\nbcbbcbcbbabcac 0.71\ncccbbbccbcabbb 6.14\nabccbcbacbacabbb 14.78\nacbcacbbcbbbcca 19.55\nbabacbbcccbcbbcbb 23.54\nacbabcbccaaab 2.69\nbbbccbabbcaab 23.97\nacbbbbcaaccccb 1.34\nbcaacacbcbaabbcbc 1.33\nbabbcabcbaaaa 4.31\nbccccaabccabcaa 9.56\nccbacbcbbccabbc 12.51\naacaabbabccca 14.74\naacaacbbbcbaabb 6.07\nbcbbcaccabaab 4.59\nacaccbcaabcbc 14.64\nbccacbaabcbabba 18.07\ncbbbaabacab 15.75\naaccbbbbbab 23.00\nacbababacbb 24.43\nbcbcbcabcabccb 3.60\nccccbcbcaccb 3.80\ncaababcabacbbb 17.87\nbcbbbbabcbc 0.20\nbacaaaabbbbbbba 0.18\nbbccbacbcabba 22.04\nacacbcbbabbba 23.14\nccacaccbba 15.75\nccbcaaabcbbaa 23.82\naabcbccbbcacbb 19.82\naccbaaababcbbbb 0.61\ncbbbaacaab 0.03\nccbccaccbcccb 18.30\nabcbcccbaaabc 16.40\nacacacbcbcabc 0.84\nccabaaaccccab 1.25\nbccbcbccacbaabc 1.93\nabcaaacbbcacbc 0.76\naabcbacbba 7.46\naabacaacbbc 5.15\nbabababacaaaaac 10.45\nbabbaabbacac 1.43\ncbbbbbcbcbbbaac 6.65\naacabbaacbba 12.23\nbcaccbababaacbabc 13.33\naccaacbbbbbcaba 0.05\nacbbabcccbb 8.84\nbcbabcbcacbbbc 21.15\nccaabaaccab 23.72\naabcabcacabaabb 14.61\nbbcbcccbaccbacc 8.64\ncacacbbabaa 10.30\ncbcbbcccaa 3.57\nbacbcbbbbacccaaaa 5.90\nacaaaacacaba 21.84\nccbaabcacccccbaa 6.05\ncbccaabbcaacab 22.62\nbbbabbbbbcb 19.93\nbababaaccaabab 17.87\nacabbbccbbac 10.52\ncbbcbbccbaa 14.83\nccabbaabaacbccbc 7.99\naacabaabbccbabcc 4.26\nccccccaccbbab 8.99\naaabaabcccbabba 16.31\nccbbacbbacac 23.64\nbaccbacacacbbbb 10.73\nacaabacbbabbbb 6.36\nbbcabababbaacaaab 4.44\nbbbbcaabbb 23.83\nccbcccacabbaa 23.75\nccbcbbbcab 19.86\nbababbcbcbaa 10.11\nbbacbbabbacc 11.28\nabbbacbbcbbacbcb 1.13\nabcbcbabaabca 24.50\ncbcaaccabb 24.34\nbabcbabbccabb 9.44\naaaabbcbccccc 18.53\ncbaccbaaca 20.23\nbbbaccacbcba 6.58\ncbabbacacaaaaa 5.47\nacbaacbababcb 4.68\nababccabcccbaacab 11.44\nbbcbabcbcbcacabcb 22.79\nbbbcaaccbbababa 24.56\naabbbccaccaba 15.98\ncbcbcabbaabbca 11.44\ncbcacbaabbcc 2.06\naccababcaab 16.25\nbcabacaaccccca 23.13\nbabbcbbcbabc 21.38\nccbcaabccaa 15.07\naaaccccaaaaaabba 13.15\nccabbcbbacbba 0.36\naacabbaccbaacabbb 20.97\nbbabaaccccccbcabc 0.99\naaacaaccbaa 1.50\nabaaaaabcaa 14.86\nabbbaabcbac 21.86\nbacbabcaab 6.26\nabbaccaabcab 1.90\nccabcabbccccbca 7.78\ncbbcbaaaaababcab 2.60\nbccbcacacbababb 23.00\ncbbabbcabcc 11.73\nabbacacacbbcbb 7.86\ncabaacabcb 7.63\nbaabbbbcaaaaac 14.77\nacaacaccbcabcb 5.86\nabbccbcbcbabca 13.16\naacbaaacbbcaaaaba 13.73\nacccbaccaaccba 10.41\nbacccabbbbac 7.68\nabccbccaaabbcc 19.60\ncabcaccbba 9.64\nbcbbbbacbcccb 7.32\nbbabbcbcacbacbbb 22.64\naababcacbca 12.72\ncbbcbacaababaaacb 8.26\naacababcabccc 22.60\nbcababcabbcbba 15.93\ncccabcacbcbababc 17.66\nccacacbbcaaabcca 21.47\nbacacaababcacbbc 10.71\nacabccbaba 24.31\nbabbacaaaabbbbcca 20.49\naabcccbaaabacabb 5.06\naabacabacbccaa 2.75\nccbbccabcabcccaac 16.28\naabcabbbbbacbca 15.62\ncabcbaaacbbabcabb 24.88\nbcacaaacaaa 15.59\nabbcbcbbccbbcbac 14.64\naccaccacbbc 21.83\nbbaabacbcccacaba 18.03\ncccaaacaaac 3.39\nbccaabcabacabcabb 8.99\nbcbaaccabbabcacc 18.93\nabcbaccacc 3.67\nccccabccccacaba 7.49\ncabcbcabcbac 16.00\ncccabcbbcacca 21.73\nbbcbacbbbcbcbbc 16.75\naaaabccbcbabbca 20.33\ncacaacabbcaaa 0.83\ncbaabcaaacaa 12.80\nbbcbbcbacabca 24.91\naabcccaaab 2.97\nccabccbbbcca 2.89\nbaabbcabbbc 11.69\nabbbcbbabbbcabbab 1.12\nbabbabbcaaabb 23.43\naacaaaacabbcaa 14.43\ncccbaabaabbccbaa 9.78\nccbcabaabbab 1.10\ncabbcbbcabbacaa 19.75\nccaabccbbaacc 22.73\nbbaccaaabc 5.19\nbacacaacabbc 20.95\ncaaaaccababaa 21.33\nabbabacaaaacc 24.24\nbabcabbabcbabbcba 7.65\nbaabbaccbaccbca 24.48\naccabbccaaaba 15.07\ncabcccaabccbcb 18.50\nbbccacabaabbcccc 10.56\ncacacaaaaaa 23.03\ncabaaaacbbacbaa 18.05\nbbbcbcaaab 20.21\nabbcabbbcaaacb 10.47\nbccaaccabbccccca 2.08\nccacbbbbaaacbaac 3.20\nbcbcabcacabbcca 24.52\nacbaababbcccaccbb 4.46\nbaabacbcbbcccab 23.51\ncbbbbcbbcccca 15.13\naacbbabccab 18.11\nabbabcacaaabb 15.36\naabbbccbccbbbac 21.95\ncbcbcbcabaacbab 13.62\nacacabcbabc 24.28\nbccaacccabcccc 23.08\nabbcccbacbabcaaba 3.69\nbccbbbbbcbccbb 12.15\nbacababcababb 11.95\nbbcaccccccabc 21.32\ncbbaabcacbc 4.38\naabbccabaccac 1.49\ncccaacccbc 15.95\naacaacbaabb 3.31\ncccaaaabbaccc 12.52\ncabacabbbcbbcccac 15.67\nbbbbcbcbbabbca 11.80\ncababbabcabaa 22.13\naababaacaccbbbbc 8.89\nabbbaabcbcbbabacc 3.75\ncbbcbbbcbabaaaaa 6.18\nccbcccbcbbbb 24.00\nbbbbccbcbb 19.98\naaaacbbcccbcbbcc 16.47\nbcbbbbbbbacabbabb 3.81\nbbbbcbbacbcacba 15.60\nbbccaccacaaa 8.22\ncbacabcbba 20.78\nbcbaabacabc 15.14\ncacbcabcbbccacbbb 16.00\nabbcabcbbb 19.64\ncbbccbbacac 19.20\nbcccbcaccccbba 7.35\ncbcbbaaaabaaaacb 21.20\nabbbabbbca 10.95\nbccaccaccc 12.25\nbccccbccaaab 15.63\ncbaccbacac 0.98\ncbacaabaaccaaacc 3.40\naccaaabbccbaaccba 16.80\nacccbaccbbaba 15.87\nacabaacacb 7.70\nbabbabcbacbabccca 5.60\nccaabbbabbcb 3.70",
          "testOut": "bbbca",
          "isValidator": true,
          "needValidation": true
        },
        {
          "title": "Another large test",
          "isTest": true,
          "testIn": "350 12\nfadaeeaf -8.26\nebbcabad 5.56\ncabbaa -5.61\nacededabac 5.57\ndebffc -9.73\neffbcdafbf 4.77\nabaaffbace -3.29\ncfabae -4.27\ndddacab 4.88\nbacadfaa 7.36\nebdceaef -8.30\nefdedcefa -3.83\ndfacbfbabe -0.71\ndcebbcb -3.15\nfdbfade -0.06\ncbdbceef -3.89\nebdbfbfd 5.12\neabdad -8.97\nbfcffefacb -4.06\nddcbcaaced -4.58\nbfaecdef 7.57\nffbfcfebde -8.42\naaeeafedd 1.66\neabdbdeed -5.84\nffaadb -5.33\nddacbddcc -4.76\nbbfacecfe 1.74\nbbcfdeaa -4.18\nfcabfbbd -0.25\necfabffc -1.53\nbeceffecd 6.54\necbcba 4.67\nabcaadac 2.97\nbbfedb -1.57\ncddcbea -2.80\ndeddecf -3.82\ndfbbabdf -7.33\ncadcde -0.59\nbbedfbc 4.42\nadfefcddf -5.47\nedecdb -9.73\ncafbbde -8.26\nfdbeafca 3.75\nfcdbbbb -0.03\nbafbeefc -8.40\neffcede -8.06\nadddeeefae 6.93\nfdefdfadc -9.32\nddcabba 8.92\nceecfbda 8.60\nadaedfdbc 5.67\nbfffda 3.72\nfbbccae -1.24\ndedeefaa 5.01\ndccbefcdaf 9.22\ndacdccfca -0.57\nbcaccac 9.93\ncceeceba 4.46\nabdfbdda 5.16\nbcbfbfb 4.68\nfeeafdfbe 1.89\nbdbefaffe 1.43\nccdfebbbf 8.96\nbfdcfcbf -9.00\ncafeffdab 9.05\nbabcefcc -7.20\nfacedcbced 9.45\nbfebfbde -5.40\nbccccfbaf -0.66\necbaccfe 2.70\nadaeeeaa 8.03\nccacacaae 7.08\nefefcc -6.86\nfdfaabde -9.17\nfafebfa -2.78\nebefcafbd -3.49\nfefacc 7.53\ndadcbaec -1.57\ndabceb -7.08\neaddeeced 5.09\nfbddfc -5.96\necccbebad -0.28\nbdbcfba -9.39\nacacabb -2.56\naafffcfdcc -8.29\nfbdcfaf -9.50\nbbebfaa 9.02\nbccafff 1.85\nfcfdafdce -8.13\ncbcfffaef -9.82\nffcede -0.31\nddaabefeb 1.91\ncbdcfafafc 0.29\naadffccaaf -0.64\nbfefdfce -1.48\nbaacbeda -3.56\nbfdcbd 8.55\nddcacb -5.71\nccdaeedb -3.67\ndbadba -6.48\ndacbaaaaad 2.84\nedbfabaefc -8.16\ndcacabdd 1.34\ncbdaaa 5.36\nfbcffacbba -2.31\naafeadf -9.10\ndfffbacbb -4.28\nffefdccad 7.58\nbdfbcbddc -8.92\nbcdcddbcd -6.61\ncfcaacfe -4.19\ndafaeb -4.55\nfccbbcf 0.33\nafebcbedfd -8.26\nabfcaca 1.91\nabedda 9.51\nfaeeebddb -9.83\ncaaffedcb 0.00\neeaebfe -8.40\nddfcfcfa 7.97\naccacca 1.29\nabbcffbbae -7.74\nfeffcdee -8.52\nabbfcb 5.30\nabfeccae -5.76\nadcdaec -7.59\nfabfaadc 6.19\ndffcaacf 9.51\nbaeabce 6.11\nbedebcfcec -4.14\nbdcccecdeb -7.61\nbccdaa -8.17\nbfcbdebcd -2.09\nffeaed -3.35\necabacbfc 8.62\ndcefeab -9.08\ndbacdddc -2.58\ndcfafbece 3.60\ndeccadddff 5.24\naceebfba -2.26\ndbbbddaa -7.25\nbacceffffe -2.82\ndabdffd 7.84\nefcaca 0.99\ndecfffe 8.52\neadfcdafb -5.94\nbacbaabad -3.77\nbdebddc -3.27\nebbefcdafb 7.34\ncafacbdee 2.33\naaceabfdfe -8.26\nacbeade -0.98\nbdbdfebad -0.56\naecaddfdf -8.08\nbfbcccffab 2.50\neeadfbaaaf 9.31\ndecefccaac -7.72\ndcfadcf -5.01\nfefeebcbe -7.91\neeffcbda -3.01\nacfbdccbad -5.05\ndaaefb -7.40\naadedbda -6.11\nbdbbbacacd -1.52\nfcffcfdac -3.02\nfbaddec 1.30\neeadeaad -4.24\neffeda 3.99\nbadffb 4.20\ncabebcba 1.47\ndbffabaaa 0.05\nceebdfccba -5.37\nfcfabef 4.42\nafbceedd 3.14\ndcfacadc -8.89\naffedbdda -2.98\nacaddbedac 3.45\nceecfccfff 9.88\nfdfeddc 9.31\nfdcbaaae 8.62\ncfcfec -5.42\nafcdca 6.49\nfcbaafdace 2.16\ndbffabebe -5.52\nafadaceb 0.17\naaecdbb 9.24\nacaaecefdc -9.66\nfdcfdefbcd -2.93\nceddacdf 8.23\ndbcbdcf -8.25\nedcddbd 1.19\ndfddfaad 2.76\necfdfcada -6.96\nfbbceed 2.03\nafacbaaa 2.28\ncfcfbaaeed -7.78\ncefddcdbe 8.45\nccebee 0.67\nefaefc -4.58\nfadbaadfe 8.10\ndfcbeefcfb 3.75\nbffbbefd -1.82\ncbfecddac 5.30\nfeabbb -8.95\nbedaacc -4.25\ncccddbac 7.94\nebfebb 9.19\ndbeeafdab 9.35\neaadefcb -3.28\naebdbadeca -1.32\nfaeebbb -5.24\nfaedef 3.73\nbfedcbce 3.62\nfefaae -8.18\neadabfabea 3.16\ncbfdec -5.84\neecffaf 5.86\ndddcfee 6.98\neccfacfed 2.48\ncccfebba 2.23\naccdbfad 5.51\nbbaecd 0.03\nfeeaddafd -5.74\nbbdaddcee 3.28\nccedddaaba 7.92\nfbdcdbcba 6.71\neaffdea 1.76\nbcccfbe 3.16\ncebabfa 6.76\nefedaddca -6.78\nefcbfd -1.36\nceeefa 7.11\nfaecbfc 2.94\neadfdecefe -4.91\neeaaeacc -4.97\nbffffcedc 8.29\ndcbbaf -8.20\nbedfaddbcc 5.90\needbaaff -0.57\nfecffa 5.10\ncafcbe 2.30\ndcbadaddf 9.43\nfbdaefc -1.94\ncebaeb -9.44\nebaceba -0.49\neccfebb -4.02\neefbbbed -7.58\ncccebefc 6.08\naefdfdbad -6.89\nedfcbad 9.84\naccafdcccb 4.42\nddaaefbf -7.32\nbbceebddfb 1.11\nafafaef 9.44\nfafdddedba -6.24\neebafb -9.20\nddcbea -6.54\nfecece 1.82\nffcfdccdff 4.39\nbadebcbf 8.50\nfcbbbd -6.25\nabecbdbe 3.96\nfdbfaddae 5.15\nefeceef -6.57\naaaccbbc -5.91\naedecadcdf 5.73\nfcfabedecb -6.40\nbabbffaf -3.02\nafcbbfcdbd 6.67\nbbaadcdeed -3.77\ndeedfbc 7.22\nceccbc 4.43\nfddafeffed 7.42\nfebcfeecca -9.35\neddffdefea 1.46\nefddbdcea -5.84\ndaefea -9.79\nbfdeeccdbf 0.66\ndbdeddfed 0.15\ndacedaaf -0.80\ncdefdcceed -4.93\naaeeaedc -4.88\nbafefbccbb -0.01\nbcafec 7.55\naeeafbcf 8.66\nacabcae -3.26\nbdcdadf 4.32\nbfaadc -5.30\nfdefaafcdd 7.64\nbcdeffab -7.49\nfdccbd -6.85\nebcafabbcd -6.19\nfeddceb 2.58\naaeadeb -7.57\nbadfacc 1.24\nccadcacda -2.67\naecfdef -8.41\nedefbafc -2.13\naaaffeeafe -3.42\neacedbcfc -8.29\nfaaceef -6.85\ndbeffacb -2.94\ncdbefc -9.51\nafbdffac -5.56\naeefdeb -3.55\ndbcbcbbdf -9.16\ncbaddefd 7.07\nfdfbcea 5.22\nefdccfbb 7.48\ndbdebabcb 0.34\nffabec -1.74\nfbaecefb 8.74\nabebecdac 0.16\nddbeaaaec -3.37\nbbaebcaa 8.41\nbbbeddded -3.14\ncfbacc 0.90\nececab 1.66\nafccadf 8.04\nadafadffec 8.52\ndbabab -7.67\nfcbaacddc 4.37\nabccaeab -7.06\nfaaabfe -7.42\naefcaab -7.31\nceebeec -9.44\nedfddfce -0.65\nefeecdaf -6.58\needceba 4.37\ndcaabac -3.17\nfabfeebbef 7.52\naafeccb -8.55\naebdcc -7.11\necbdba 5.50\ndabcdf -4.92\nabdeedf 2.02\neebcaafde 8.02\nafdfcdfa -4.03\nfcdaafcec 7.36\nbcfaaabffd -6.32\nefeacb -9.70\nfebaeddec -5.65\nbefcffacd 4.09\ndfabecdf 0.52\nfacadbceeb 2.48\nccbfcead 3.99\ndcdbcfbdac 3.14\ndbfbcdbec -0.63\nffdcdcdccd 6.72\nfcadbcc 1.18",
          "testOut": "ccb",
          "isValidator": false,
          "needValidation": true
        },
        {
          "title": "Another large validator",
          "isTest": false,
          "testIn": "403 1.41\nbaaabaaaab 0.91\nbabbbabbbbab 0.74\nbabbababbaa 0.78\nbababaabbbbbbb 0.18\nbaabbbabbbbbab 0.50\nbbababbaabbbaaa 0.53\nabbbbabbaaa 0.57\nbbbabbabaabbbbaa 0.95\nbbabbaaaaaaaa 0.24\nabbbbaaaaaabbb 0.66\nbaababaaababb 0.12\nbbbbabababababab 0.36\nababbabbabaabbaa 0.48\naababaaabbabbba 0.14\nabaabaabbaababaa 0.23\nbbabbaabbbaa 0.30\nabbabbbbabbbbab 0.96\naaaababbba 0.23\nbbaabaabbbba 0.85\nbbaaabbbbba 0.64\nbbbbabaaba 0.30\naaaaabababbbb 0.53\nbbbbaaaaaa 0.88\nbabaaaabbaa 0.63\nbababaababbaaba 0.41\nbaabbbabbbbbb 0.33\nabaaaaaaab 0.30\nbbababbbbbbababb 0.23\nbbabbbbbabbaaba 0.86\nbabbbabaaaba 0.11\nbbabaabaabbabbbb 0.10\nbbbaaababbbbabb 0.88\naaaabaabbb 0.14\nabbabbabbbbb 0.97\nbaaaabbbaabbaaa 0.73\naabbabbbabbbaa 0.34\nbbbbbbaaab 0.51\nbbbbbabaaabba 0.17\naaaabbbaba 0.40\nbbabbabbbbaabaa 0.55\nbabbbbaaaaaaaab 0.07\nbbaabbaabbaa 0.15\nbbaaabaabbb 0.35\nbabbbabbbbb 0.93\nabbbbaabaabaa 0.66\nbbbbabaaabaaaa 0.41\nbbababbbbaababa 0.61\nabababaaabbaab 0.86\naaabaabbbaa 0.82\nbbbbaaabaa 0.17\nbaabababaabbba 0.03\nbababbaaabbab 0.02\naaaaaaabab 0.13\nabaaaaaaaaa 0.98\nbabaabbababaabaa 0.01\nbaabbaaabbaabab 0.45\nbbbbaababbb 0.60\nabaababaaa 0.27\naabbbaabbaa 0.83\nabbbbabbabb 0.93\nabaababaaa 0.14\nabaaaabbababaaa 0.39\nabaabbaaba 0.86\naaaaababaabaab 0.31\nabbababababaaabb 0.50\nbaabaaaabaaaabba 0.13\nabbbaaabbaa 0.69\naaaaababbababba 0.52\naaabbabaaabba 0.96\nbabaaaabaaaabab 0.54\naababaaaaba 0.99\naababbababbabaab 0.58\nbaaaaaabaaba 0.58\nbaaabbbaabbbab 0.12\nbbaaabbbaababbbb 0.01\nabbbbaaaabaa 0.22\nbbaabaabaabbaa 0.12\nabbbabaaababaaaa 0.56\nabababbbbbabba 0.61\nbbbbaababbaaaa 0.10\nababaababaaaaab 0.22\nbbaaaaaabbbbaaa 0.64\nbbbaabbaaabaa 0.17\nbbbaabbaabbbba 0.71\nabaaabbaabbab 0.38\nabbaaabbbbaabaa 1.00\nbabbabbbaaabbbb 0.60\naabbaababbaaba 0.99\nabaababbbbabaa 0.07\nabbbaabaabbb 0.97\naabaababbaabbba 0.75\naabbbbbbaababa 0.98\naaabbbaabbbaabaa 0.56\nbbbbbabbabbabbb 0.32\nbaaabaaabab 0.65\nbaaaaabbaba 0.52\nbbaaabbbbaaaaaba 0.28\nbabbbabbbaababba 0.01\nababbababababa 0.99\naaaaabaaababa 0.78\nbbbaaaabababbbb 0.84\naaaabaaaaab 0.91\nabaabbbbbbbbbbab 0.10\nbaababbbbaaab 0.66\naabbabaabbababaa 0.95\nabbaabbbbbab 0.52\nbaaaaaabbb 0.44\naabbaaaaaaaa 0.49\naaabbaaabaaabbaa 0.84\nababaaabababb 0.85\nababbabbaaa 0.00\nbbbabbbabbaab 0.60\nbbaabbbbabbbbb 0.13\nbaaabbbbbbbaabaa 0.68\nabbabbbbbbb 0.01\nbabaababaabaaa 0.55\nbbbaaaabbbabba 0.87\nbaaaababaaabbaa 0.65\nbabbababaabab 0.21\naaabababbabbba 0.09\nbaaabbababbaabb 0.56\naaabbbaaabb 0.74\nbabaaaaabbbbabb 0.30\nabbabaabaabaaba 0.81\naaaabbabbbb 0.29\nbbabababaaaba 0.20\nbaabbbababbaab 0.03\naabbbabbaaab 0.83\nbbabaabaababba 0.42\nbaaabbabbaab 0.82\nabbabaabbbbbaaab 0.54\naaababbabbb 0.59\nbbabababaababb 0.10\nbabaaaaaaabb 0.84\nbbababbbabbba 0.19\nbabbaabbbbabbbaa 0.60\naabaaabbabaabaaa 0.62\nbbbabbaaabbbaaaa 0.61\nbbbbbbabaaa 0.57\naaaaaabbaabb 0.30\naaaabbbbababbbab 0.37\naabbabaabbabaa 0.18\nbbaabbaaabababa 0.91\naaabaabaabbbbb 0.14\nababababbbbaa 0.47\nbbaabbababaaa 0.95\nabbbbaabbbbb 0.49\nabababbbbbb 0.02\nbbabbbabbbabaab 0.28\nababbabaaba 0.25\nbbbbbabaabbaa 0.96\naaaaaabbbbbbbb 0.86\nbabaaabbbaab 0.71\nbabbababbbbbba 0.33\nbaaabbabbaba 0.06\nbbabbbbbaaab 0.89\nbbabaabbaabbba 0.88\nbbbbbabaaba 0.15\nabbbabbabbabbba 0.74\nabbbaabbaabb 0.31\naaabbbbabbabaa 0.39\nbbabbababbbb 0.68\nabbaabbabaabb 0.62\nbaababbbbbb 0.29\naabbbbabbbbabb 0.46\nbbabbbababa 0.02\nbaaabaaabbbbb 0.56\nabbaaabababaabaa 0.13\naaabbbabbbaaabab 0.76\nbbaabbaaaa 0.77\nabbababbaaa 0.81\nbabbbabbabbbaaba 0.43\nababaaaaaabb 0.48\nbbbbbbbaaba 0.88\nbbbbbabbababa 0.01\nababbaabbbb 0.11\nbaabbaaaaabbb 0.77\nbbbbbaabbabbbbaa 0.32\nbaaabaabababaaba 0.49\nbbaabaababbababa 0.95\nabbababaabbbbb 0.25\nbabbaaabbabbaa 0.12\nbbbbbbbbbabbbaaa 0.16\nabaabbbbba 0.45\nbbbabaaaaabaaa 0.06\nbbbbabbbabaaa 0.96\naabbaaabbba 0.22\nbbbaaaaaaaa 0.58\naaaaabaaabb 0.29\nbbaaaaabbbaaabaa 0.66\naaabaababbbaaa 0.44\nbbabbbaaaabaaa 0.99\nbbbaaaabaaab 0.53\nbbabaaaabaabbb 0.32\nbbbbabbbbbb 0.61\naabbbbbababbab 0.50\nbabbbabaaaaba 0.11\nabbbbabbbb 0.56\nbbbbbaabbaaaabba 0.59\naaaabbbabbbababb 0.96\nbaaaabaabbbb 0.10\nbbabbabbaaabaab 0.09\nbababbabaa 0.78\nbbbbbbbbbb 0.82\naaaaaaabbbaaaba 0.90\nbabbabbbaabbabb 0.08\nbababbbbabbbaa 0.73\naaababaabb 0.28\nbaabababaaa 0.82\nbbbabaabbaaab 0.88\nbababaaaaba 0.87\naababbaabbbb 0.94\naababababa 0.10\nbbbbababbabab 0.09\nbaaaaabbaabbab 0.59\naababbbababbaaa 0.78\nbbbaaabaabababab 0.91\naabaaabbbaaa 0.67\nbaaaaaaaaabbab 0.98\nabbababbabbb 0.43\nbaabaabbbbab 0.52\naabbbbbabb 0.44\nabababbbabbb 0.68\nbaaaabaaaaabb 0.89\nbaababbaba 0.36\naaaababbaaabbb 0.70\naaaabbbaabab 0.42\nbabaaaabbbbbaa 0.49\nbbabaaabbbb 0.17\nabaaabaaababbab 0.97\nbbbaaaabbaaba 0.76\nbabbaabbbbba 0.26\nbabaabababbaabb 0.17\nabbabbabaaaa 0.32\nbaabbbbabaaaaaba 0.79\nbbabbaabbbb 0.12\nbaaaabbbbaa 0.70\nbbabbaaabb 0.14\naabbabbaabbababa 0.30\naabbbbababaabaa 0.28\naabbbbbaab 0.87\nbabababaaabb 0.96\nbabbabaabba 0.16\naabaabbabbaaaaa 0.47\nbaaabbaaba 0.55\naaabababbabbaaba 0.51\nbbbbbbbbbaaa 0.68\nbaabbaabaaabbbaa 0.53\nbaabaabbaabbaabb 0.95\naaababbbbbababb 0.34\nabaaaaababb 0.36\naaaabbababbb 0.28\nababbbbaaaabab 0.48\naabaabaaaa 0.55\naabbbaaababbbabb 0.68\nbbaaaaaaabbbba 0.99\nabbbabbbaabaa 0.42\naaabbbababbaa 0.68\nbaaaaaaaabbb 0.74\nbbaababaab 0.37\nbaabbbbabbbabaab 0.89\nababbbaaababba 0.35\naaabaabaaa 0.91\nababbbabab 0.30\nbbbaaabbbbbaaaaa 0.41\nababaabbbaaaaab 0.01\nabbababbbabb 0.78\nababbaabaaaaab 0.04\nbaabaaabbbaa 0.20\nbbaabbaaabbabb 0.66\nbbabaaaaaaab 0.68\nbabaababbaaab 0.19\naababaaaaabbbbbb 0.79\naaabbbbbbaa 0.41\nababaababbabaab 0.85\nbabaabbabbbbaa 0.62\naaabaaabbb 0.60\nbabbaaaaaab 0.27\naabaaaabababaa 0.87\nbbbabababbbb 0.32\naabbababbb 0.97\nbabaaabbbba 0.09\nbbabbaababa 0.59\nababaabaabbbbaaa 0.94\nbababbbbba 0.51\nbbabaaaabb 0.71\nbbbaabaabbabb 0.15\nbabababaab 0.81\nabaaabbbaa 0.84\nabbaaabbaab 0.78\nbbaabbbabaab 0.08\nbbaabbabbbbabaab 0.21\nbbbaaabaaaab 0.59\naabbbaaaababa 0.41\nbabbbbabbbaaabaa 0.72\nabbbaaaabba 0.69\nbabaabbbbabaabaa 0.34\naabbbbaabbaab 0.19\nabbabaabbaaabbba 0.54\nbaabaabaaabbabaa 0.54\nbbabaabababbb 0.31\nbbbbbaaabaabbaba 0.77\nabbbaabaaabaa 0.15\naabaaabbabbbbba 0.32\nabbbbaaababb 0.92\nbbbabbbaab 0.15\naaabbbaabaabb 0.85\nabaaaabababbaa 0.37\nbbbabaabaabb 0.16\nababbbbaaaaabaa 0.19\naaabaaababbbbaba 0.43\nbbbbabbbaaba 0.94\nbbbbaaaaabbbaba 0.01\nabbabbabba 0.83\nbababbbaabaaa 0.73\naaaaaaaabbaa 0.79\nbbabaaabab 0.09\naaabababbbabbbb 0.36\naababbbbaaababa 0.88\nbbbbaabaaaba 0.12\nbaabaabbababab 0.17\naaaabbaabb 0.90\naaabbbbaaaa 0.28\nbaaaabaaaba 0.82\nbbaabbbbbaaaab 0.93\naabaaaaaabbabbba 0.75\nbababbbabbaaa 0.98\nbababaaababbbba 0.84\nbbbaaabaaababaab 0.60\nabaabbbbaa 0.52\nbabbbbabbbbb 0.88\nabbaaababaaaba 0.02\nbabbabaaabaaaba 0.29\naaaaaabababb 0.22\naababaabab 0.29\nabbaaabbbaaaab 0.03\naabababaabbbab 0.15\naaaaaaabbabbaa 0.05\nabababbabbbb 0.39\nbbabaabbbabbaaab 0.02\nbaabaaaabbabbab 0.51\naabaaaaabbba 0.68\naabbababaaa 0.69\naaabaabaaa 0.91\nabbabbbbabaaabab 0.73\nbababbbaaabbbba 0.32\naaabaababa 0.66\naababbaaabbaaa 0.47\nbbabbabbbbb 0.45\nbbaaabbabababab 0.73\nbabaabbbaab 0.11\nbaabbaabab 0.74\nbaabaabaabaa 0.08\nabbbbbaabaaaaaba 0.28\nbbaaaabbabaaa 0.89\naabbaaabab 0.22\naaaaaaabaa 0.16\nbabaabaabbbaabbb 0.59\nbabbabaaaaa 0.14\nabaabaaabba 0.06\nbbbbaabaabaa 0.95\nabababaababa 0.80\nabbaaaababbbbb 0.57\nabbbbbabbb 0.25\nabbaabaaaa 0.47\naaabbabbaabab 0.52\nbaababbaba 0.23\nabbbaabbbba 0.07\naababbabbaba 0.11\nabbbabaabb 0.30\nbbbbbaabab 0.33\nbbaabbaabbb 0.88\nbaabaababaab 0.17\nbbbbbbababbaab 0.16\nbbbbbaaabaaaa 0.26\nbaaabbaaaaaaa 0.21\nbabaabbabba 0.83\naaabaabaabbba 0.24\nabaaaababb 0.83\nbababbbabbba 0.90\nababaabbbbabaaba 0.60\naababbababa 0.87\nbbbabaabbb 0.42\naabaabaabbabb 0.23\naaabbbbbabb 0.34\nbabbaaaaabbaa 0.97\nbaaaabaababb 0.95\nbaaaaabaaaaab 0.67\naabbaaabbaa 0.29\nbbabbbabbbb 0.52\nbabbbbbbba 0.95\nbaaabbbbabaaba 0.38\nbbaabaaabbbaabbb 0.28\nabababaabbb 0.10\nbaabbabaaaabbaaa 0.13\nabaaaabbaa 0.86\nabbaaaabaa 0.49\nabbbaabbbbbbaa 0.03\naaabaabbaaa 0.98\naababbbaabbabbb 0.23\nbaaaaabbbab 0.99\nbbbbabaabbbbb 0.70\nabaaaaabaaa 0.47",
          "testOut": "aabbbaaa",
          "isValidator": true,
          "needValidation": true
        }
      ],
      "difficulty": "hard",
      "constraints": "0 < [[N]] < 500\n0 < playout length  < 50\n1 < branching factor  < 10\n-100.1 < score (playout's result) < 100.1",
      "coverBinaryId": 138086606975225,
      "stubGenerator": "read N:int C:float\nloop N read playout:word(50) score:float\nwrite aaaaaaaa",
      "inputDescription": "<<Line 1:>> 2 space-separated values: \nan integer [[N]] - the number of performed playouts\na real number [[C]] - the constant C (the exploration parameter)\n\n<<Next [[N]] lines:>> Sequence of movements performed in this playout, followed by a space, followed by the playout's result",
      "solutionLanguage": "Python3",
      "outputDescription": "Sequence of movements that will be chosen in the MCTS tree using UCB1 selection."
    },
    "draft": false,
    "readyForModeration": true,
    "statementHTML": "<div class=\"statement-body\">\n<div class=\"statement-section statement-goal\">\n   <h2><span class=\"icon icon-goal\">&nbsp;</span><span>Goal </span></h2>\n   <span class=\"question-statement\">Assume we are dealing with (nondeterministic) one-player game. To find an optimal sequence of movements we could use Monte Carlo Tree Search algorithm (https://en.wikipedia.org/wiki/Monte_Carlo_tree_search). <br><br>Thus, we perform a number of so-called playouts, and gradually build an MCTS tree that will help us choosing statistically best choices for each turn of the game. A playout is a sequence of moves reaching the game tree leaf, so it has assigned a true score. It consists of two parts: the beginning, which is selected by the algorithm using the UCT formula; and the remaining part which is usually a random sequence of movements.<br><br>In this puzzle, we are given a list of playouts (encoded as words, where each letter is a single move) with assigned scores, that should be used to build an MCTS tree. After building a tree, the task is to return the sequence of moves, reaching the MCTS tree leaf, that will be chosen using UCT policy given exploration/exploitation constant <const>C</const>.<br><br>For given node <var>N</var> visited <var>N.v</var> times, according to the UCB1 formula we should choose a child <var>M</var> that maximizes the value given by: <var>M.s/M.v + C*sqrt(ln(N.v)/M.v)</var>, where <var>M.v</var> is number of visits in node <var>M</var> and <var>M.s</var> is sum of scores obtained for this node (so the first component of the sum is average score for node <var>M</var>).<br><br><strong>Final remarks:</strong><br>- Note that this puzzle differs form the real-life-scenario where the playouts are not given, but they are also computed using UCT+random policies.<br>- In standard implementations you are forced to choose an unexplored move if such exists. Here we assume that after reading the playout data we do not have such moves in the non-leaf nodes of the MCTS tree.<br>- A tie-breaking rules when comparing UCT values is the ordering on letters (i.e. smaller letter should be chosen).<br><br><strong>Example explanation:</strong><br>- Reading <const>baa 30</const> will create child node labeled <const>b</const> with avg. score 30 and one visit. The MCTS tree root will have the same statistics. Note that we are adding only one new node at a time.<br>- Reading <const>ab 20</const> will create another child node for the root, updating its statistics.<br>- Finally, reading <const>bbb 4</const> will create a new node on a path <const>bb</const> from the root, updating all statistics on a way to the root, so the root will have 3 visits, and <const>b</const> node 2 visits.<br>- Choosing move from the root based on the UCB1 formula will favor move <const>a</const> (average score 20), instead of move <const>b</const> (average score 17). This is because the small value of constant <const>C</const>, makes the exploration part of the equation not significant.<br>- As there are no further nodes in MCTS tree along that paths, the 1-move sequence <const>a</const> is the answer.</span>\n</div>\n<div class=\"statement-section statement-protocol\">\n   <div class=\"blk\">\n      <div class=\"title\">Input</div>\n      <div class=\"question-statement-input\"><strong>Line 1:</strong> 2 space-separated values: <br>an integer <var>N</var> - the number of performed playouts<br>a real number <var>C</var> - the constant C (the exploration parameter)<br><br><strong>Next <var>N</var> lines:</strong> Sequence of movements performed in this playout, followed by a space, followed by the playout's result</div>\n   </div>\n   <div class=\"blk\">\n      <div class=\"title\">Output</div>\n      <div class=\"question-statement-output\">Sequence of movements that will be chosen in the MCTS tree using UCB1 selection.</div>\n   </div>\n   <div class=\"blk\">\n      <div class=\"title\">Constraints</div>\n      <div class=\"question-statement-constraints\">0 &lt; <var>N</var> &lt; 500<br>0 &lt; playout length  &lt; 50<br>1 &lt; branching factor  &lt; 10<br>-100.1 &lt; score (playout's result) &lt; 100.1</div>\n   </div>\n   <div class=\"blk\">\n      <div class=\"title\">Example</div>\n      <div class=\"statement-inout\">\n         <div class=\"statement-inout-in\">\n            <div class=\"title\">Input</div>\n            <pre class=\"question-statement-example-in\">3 0.1\nbaa 30\nab 20\nbbb 4</pre>\n         </div>\n         <div class=\"statement-inout-out\">\n            <div class=\"title\">Output</div>\n            <pre class=\"question-statement-example-out\">a</pre>\n         </div>\n      </div>\n   </div>\n</div>"
  },
  "validatedFor": 258945106576,
  "avatar": 4210501575817,
  "commentCount": 16,
  "upVotes": 25,
  "downVotes": 1,
  "validateAction": {
    "actionId": 171642,
    "progress": 1,
    "alreadyDone": false
  },
  "statusHistory": [],
  "editable": true,
  "draft": false,
  "readyForModeration": true
}