{
  "id": 5548,
  "activeVersion": 16,
  "score": 5,
  "votableId": 15314473,
  "codingamerId": 4005194,
  "views": 184,
  "commentableId": 15230620,
  "title": "Finding the Highest Entropy Word",
  "status": "ACCEPTED",
  "type": "CLASHOFCODE",
  "nickname": "K-",
  "publicHandle": "55485942ecbbebb38b7165c20a5404d54c79",
  "codingamerHandle": "75a83bc3873b689b84deaa63c266e3554915004",
  "lastVersion": {
    "version": 16,
    "autocloseTime": 1604929990464,
    "data": {
      "title": "Finding the Highest Entropy Word",
      "topics": [],
      "fastest": true,
      "reverse": false,
      "shortest": true,
      "solution": "import math\n\ndef occurence(letter,word) :\n    i = 0\n    for c in word :\n        if c==letter:\n            i+=1\n    return i\n\ndef entropy(word):\n    i = 0\n    size = len(word)\n    existing = []\n    for c in word :\n        if c not in existing :\n            p = occurence(c,word) / size\n            i+= (-p)*math.log2(p)\n            existing.append(c)\n        else :\n            pass\n    return i\n\nn = int(input())\nwords = []\nfor i in range(n):\n    w = input()\n    words.append((w,entropy(w)))\n\nprint(max(words, key=lambda x:x[1])[0])",
      "statement": "Given a list of [[N]] words, calculate the entropy of each individual word and print the word with the highest entropy. \n\n<<Explanations:>>\nThe entropy of a word is a measure of how much information it gets across.\n\n<<Goal:>>\nCalculate the entropy of each word, and then print the word with the highest entropy\n\n<<Calculation:>>\nLet's take the word <<hello>> as an example. First, we need to calculate the probability of each individual character as follows:\n`                number of occurrences of the character in the word     \nP(character) = ----------------------------------------------------\n                         number of characters in the word`\nIn this example <<hello>>, the probability of the letter <<l>> (ell) would be:\n`          number of characters 'l' in the word     2 \nP('l') = -------------------------------------- = --- = 0.4\n             number of characters in the word      5`\nFor all the letters we get:\n`p(h) = 0.2\np(e) = 0.2\np(l) = 0.4\np(o) = 0.2`\n\nThe entropy of a word is given by <<sum of (-P(x) log_2(P(x)) ) >> where <<P(x)>> is the probability (as defined before hand) of each <<distinct>> character and log_2 is the base 2 logarithm.\nFor the example <<hello>>, its entropy would be:\n`-p(h) * log_2(p(h)) - p(e) * log_2(p(e)) - p(l) * log_2(p(l)) - p(o) * log_2(p(o)) \n= -0.2 * log_2(0.2) - 0.2 * log_2(0.2) - 0.4 * log_2(0.4)  - 0.2 * log_2(0.2)`",
      "testCases": [
        {
          "title": "Test 1",
          "isTest": true,
          "testIn": "2\nppr\nhello",
          "testOut": "hello",
          "isValidator": false,
          "needValidation": false
        },
        {
          "title": "Validator 1",
          "isTest": false,
          "testIn": "3\nabc\nabcd\nabcde",
          "testOut": "abcde",
          "isValidator": true,
          "needValidation": false
        },
        {
          "title": "Test 2",
          "isTest": true,
          "testIn": "2\nthisisagoodone\nthisisagoodonex",
          "testOut": "thisisagoodonex",
          "isValidator": false,
          "needValidation": false
        },
        {
          "title": "Validator 2",
          "isTest": false,
          "testIn": "2\naaaaa\naataa",
          "testOut": "aataa",
          "isValidator": true,
          "needValidation": false
        },
        {
          "title": "Test 3",
          "isTest": true,
          "testIn": "2\nabcdefghijklmnopqrstuvwxyz\naaaaaaaaaaaaaaaaaaaaaaaaaa",
          "testOut": "abcdefghijklmnopqrstuvwxyz",
          "isValidator": false,
          "needValidation": false
        },
        {
          "title": "Validator 3",
          "isTest": false,
          "testIn": "2\nsolution\nnosolution",
          "testOut": "solution",
          "isValidator": true,
          "needValidation": false
        },
        {
          "title": "Test 4",
          "isTest": true,
          "testIn": "3\ntan(x) = sin(x) / cos(x)\ncot(x) = cos(x) / sin(x)\ncos(x)^2 + sin(x)^2 = 1",
          "testOut": "cos(x)^2 + sin(x)^2 = 1",
          "isValidator": false,
          "needValidation": false
        },
        {
          "title": "Validator 4",
          "isTest": false,
          "testIn": "4\nabsolute\nabsolutely\nisatruth\nhowever",
          "testOut": "absolutely",
          "isValidator": true,
          "needValidation": false
        },
        {
          "title": "Test 5",
          "isTest": true,
          "testIn": "3\n0101010101010\n0010111011011\n0000001110000",
          "testOut": "0101010101010",
          "isValidator": false,
          "needValidation": false
        },
        {
          "title": "Validator 5",
          "isTest": false,
          "testIn": "4\n0101010101010111\n0010111011010100\n0000001110000111\n0000000000000001",
          "testOut": "0010111011010100",
          "isValidator": true,
          "needValidation": false
        },
        {
          "title": "Test 6",
          "isTest": true,
          "testIn": "2\nz_is_a_no_frequent_letter\ne_is_a_frequent_letter",
          "testOut": "z_is_a_no_frequent_letter",
          "isValidator": false,
          "needValidation": false
        },
        {
          "title": "Validator 6",
          "isTest": false,
          "testIn": "3\n0_is_the_smallest_digit\n1_is_the_bigest_digit\n+_is_not_a_digit",
          "testOut": "0_is_the_smallest_digit",
          "isValidator": true,
          "needValidation": false
        },
        {
          "title": "Test 7",
          "isTest": true,
          "testIn": "22\nlogical\ncogent\nobvious\ncoherent\nplausible\ncompelling\nrational\nconsistent\nrelevent\nconvincing\nsensible\nintelligent\nvalid\nlegitimate\nwise\nlucid\nnecessary\nanalytical\nclear\ncongruent\ndeductible\nconsequent",
          "testOut": "compelling",
          "isValidator": false,
          "needValidation": false
        },
        {
          "title": "Validator 7",
          "isTest": false,
          "testIn": "22\nlogicaly\ngiving\nobvious\napprove\nplausible\nhey\nrational\nmath\nrelevent\nconvincing\nclever\nintelligent\nsmart\nlegitimate\nzzzzzz\nlucid\nnecessary\nbigdata\nclear\nalgorithm\ndeductible\nconsequent",
          "testOut": "algorithm",
          "isValidator": true,
          "needValidation": false
        }
      ],
      "constraints": "2 ≤ [[N]] ≤ 25\n2 ≤ [[word size]] ≤ 100",
      "stubGenerator": "read n:int\nloop n read word:string(1024)\nwrite answer",
      "inputDescription": "<<Line 1:>> An integer [[N]] representing the number of words to be analyzed\n<<Next [[N]] lines:>> A string [[word]]",
      "solutionLanguage": "Python3",
      "outputDescription": "<<Line 1:>> The word with the highest entropy"
    },
    "draft": false,
    "readyForModeration": true,
    "statementHTML": "<div class=\"statement-body\">\n<div class=\"statement-section statement-goal\">\n   <h2><span class=\"icon icon-goal\">&nbsp;</span><span>Goal </span></h2>\n   <span class=\"question-statement\">Given a list of <var>N</var> words, calculate the entropy of each individual word and print the word with the highest entropy. <br><br><strong>Explanations:</strong><br>The entropy of a word is a measure of how much information it gets across.<br><br><strong>Goal:</strong><br>Calculate the entropy of each word, and then print the word with the highest entropy<br><br><strong>Calculation:</strong><br>Let's take the word <strong>hello</strong> as an example. First, we need to calculate the probability of each individual character as follows:<br><pre style=\"font-family: monospace\">                number of occurrences of the character in the word     <br>P(character) = ----------------------------------------------------<br>                         number of characters in the word</pre><br>In this example <strong>hello</strong>, the probability of the letter <strong>l</strong> (ell) would be:<br><pre style=\"font-family: monospace\">          number of characters 'l' in the word     2 <br>P('l') = -------------------------------------- = --- = 0.4<br>             number of characters in the word      5</pre><br>For all the letters we get:<br><pre style=\"font-family: monospace\">p(h) = 0.2<br>p(e) = 0.2<br>p(l) = 0.4<br>p(o) = 0.2</pre><br><br>The entropy of a word is given by <strong>sum of (-P(x) log_2(P(x)) ) </strong> where <strong>P(x)</strong> is the probability (as defined before hand) of each <strong>distinct</strong> character and log_2 is the base 2 logarithm.<br>For the example <strong>hello</strong>, its entropy would be:<br><pre style=\"font-family: monospace\">-p(h) * log_2(p(h)) - p(e) * log_2(p(e)) - p(l) * log_2(p(l)) - p(o) * log_2(p(o)) <br>= -0.2 * log_2(0.2) - 0.2 * log_2(0.2) - 0.4 * log_2(0.4)  - 0.2 * log_2(0.2)</pre></span>\n</div>\n<div class=\"statement-section statement-protocol\">\n   <div class=\"blk\">\n      <div class=\"title\">Input</div>\n      <div class=\"question-statement-input\"><strong>Line 1:</strong> An integer <var>N</var> representing the number of words to be analyzed<br><strong>Next <var>N</var> lines:</strong> A string <var>word</var></div>\n   </div>\n   <div class=\"blk\">\n      <div class=\"title\">Output</div>\n      <div class=\"question-statement-output\"><strong>Line 1:</strong> The word with the highest entropy</div>\n   </div>\n   <div class=\"blk\">\n      <div class=\"title\">Constraints</div>\n      <div class=\"question-statement-constraints\">2 &le; <var>N</var> &le; 25<br>2 &le; <var>word size</var> &le; 100</div>\n   </div>\n   <div class=\"blk\">\n      <div class=\"title\">Example</div>\n      <div class=\"statement-inout\">\n         <div class=\"statement-inout-in\">\n            <div class=\"title\">Input</div>\n            <pre class=\"question-statement-example-in\">2\nppr\nhello</pre>\n         </div>\n         <div class=\"statement-inout-out\">\n            <div class=\"title\">Output</div>\n            <pre class=\"question-statement-example-out\">hello</pre>\n         </div>\n      </div>\n   </div>\n</div>"
  },
  "validatedFor": 167699716128,
  "avatar": 51409724336380,
  "commentCount": 28,
  "upVotes": 7,
  "downVotes": 2,
  "validateAction": {
    "actionId": 498643,
    "progress": 1,
    "alreadyDone": false
  },
  "statusHistory": [
    {
      "status": "ACCEPTED",
      "date": 1603031172884,
      "data": {
        "author": "ACTION"
      }
    }
  ],
  "editable": true,
  "draft": false,
  "readyForModeration": true
}